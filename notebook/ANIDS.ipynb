{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rosangithub/ANIDS/blob/main/ANIDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZGZ_2Tob32K"
   },
   "source": [
    "# Anomaly Based Network Intrusion Detection System using Ensemble Machine learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_M4ntb-DbiaC"
   },
   "outputs": [],
   "source": [
    "import numpy as np#linear algebra\n",
    "import pandas as pd#data preprocessing,CSV files\n",
    "import pickle#saving and loading trained model\n",
    "from os import path\n",
    "#importing required libraries for normalizing data\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import(StandardScaler,OrdinalEncoder,LabelEncoder,MinMaxScaler,OneHotEncoder)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import Normalizer,MaxAbsScaler,RobustScaler,PowerTransformer\n",
    "#importing library for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m      2\u001b[39m drive.mount(\u001b[33m'\u001b[39m\u001b[33m/content/drive\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google.colab'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "dd27BUOgfq37",
    "outputId": "fb9579be-3983-403a-807f-99e6f8254234"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#Read all the csv files and combine them into one dataframe\u001b[39;00m\n\u001b[32m      7\u001b[39m df_list=(pd.read_csv(file) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m csv_files)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m df=\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m df.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[39m, in \u001b[36mconcat\u001b[39m\u001b[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[32m    380\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m op = \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[39m, in \u001b[36m_Concatenator.__init__\u001b[39m\u001b[34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[39m\n\u001b[32m    442\u001b[39m \u001b[38;5;28mself\u001b[39m.verify_integrity = verify_integrity\n\u001b[32m    443\u001b[39m \u001b[38;5;28mself\u001b[39m.copy = copy\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m objs, keys = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[32m    448\u001b[39m ndims = \u001b[38;5;28mself\u001b[39m._get_ndims(objs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:507\u001b[39m, in \u001b[36m_Concatenator._clean_keys_and_objs\u001b[39m\u001b[34m(self, objs, keys)\u001b[39m\n\u001b[32m    504\u001b[39m     objs_list = \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo objects to concatenate\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    509\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    510\u001b[39m     objs_list = \u001b[38;5;28mlist\u001b[39m(com.not_none(*objs_list))\n",
      "\u001b[31mValueError\u001b[39m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "#path to your folder containing csv files\n",
    "folder_path=\"/content/drive/MyDrive/data/raw/\"\n",
    "#get  a list of all csv files in the folder\n",
    "csv_files=glob.glob(folder_path + \"*.csv\")\n",
    "#Read all the csv files and combine them into one dataframe\n",
    "df_list=(pd.read_csv(file) for file in csv_files)\n",
    "df=pd.concat(df_list,ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jGL2xozQgf-7",
    "outputId": "0ce35c2f-2224-4198-c6fc-6f23c8ca74a7"
   },
   "outputs": [],
   "source": [
    "#display the shape and the find the concatinated dataframe\n",
    "nRow,nCol=df.shape\n",
    "print(f\"Rows:{nRow},Columns: {nCol}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "4wNKapnple6y",
    "outputId": "c83fcb3b-532b-4742-a65a-16f75791f3e2"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qhWoAemVmXvq",
    "outputId": "52b70f19-814c-468d-daf9-10f9386f7948"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "zIg9q_k9mbHp",
    "outputId": "731d85d4-e3de-4c7b-cb40-0df04e070075"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYsrGx6Ampr5",
    "outputId": "6320c27e-3f59-4b6c-f4b0-df7431bb82d1"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "AlQd0WwkmyP5",
    "outputId": "63b2b4d1-4d51-4663-8bd9-1c91bfae68c1"
   },
   "outputs": [],
   "source": [
    "df.columns=df.columns.str.strip()\n",
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eywQBgQnqyb"
   },
   "source": [
    "## Remove the missing values NaN from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aTPRB_9Um3Yx"
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "id": "O4vijDcFnPGq",
    "outputId": "60b603b0-6564-4a08-e2cf-ef11c448947f"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDoAx2UBn9Dy"
   },
   "source": [
    "## Plotting the histogram of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gp4RoSRtnQgJ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # for plotting graphs\n",
    "import numpy as np               # for numerical operations and dtype checking\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_per_column_distribution(df, n_graph_shown, n_graph_per_row):\n",
    "    \"\"\"\n",
    "    This function plots the distribution of values for multiple columns in a DataFrame.\n",
    "    Numeric columns are shown as histograms.\n",
    "    Categorical columns (with few unique values) are shown as bar charts.\n",
    "\n",
    "    Parameters:\n",
    "    df: pandas DataFrame\n",
    "        The dataset containing columns to plot\n",
    "    n_graph_shown: int\n",
    "        Maximum number of columns to plot\n",
    "    n_graph_per_row: int\n",
    "        Number of plots to show in each row\n",
    "    \"\"\"\n",
    "\n",
    "    # Count unique values in each column\n",
    "    nunique = df.nunique()\n",
    "\n",
    "    # Select columns with 2 to 49 unique values for plotting\n",
    "    columns_to_plot = df.columns[(nunique > 1) & (nunique < 50)]\n",
    "    print(columns_to_plot)\n",
    "\n",
    "    # Create a smaller DataFrame containing only selected columns\n",
    "    df_to_plot = df[columns_to_plot]\n",
    "\n",
    "    # Get the number of rows and columns in the filtered DataFrame\n",
    "    n_rows, n_cols = df_to_plot.shape\n",
    "\n",
    "    # Calculate how many rows of plots we need in the figure\n",
    "    n_graph_row = (n_cols + n_graph_per_row - 1) // n_graph_per_row  # integer division\n",
    "\n",
    "    # Create the figure with calculated size\n",
    "    plt.figure(num=None,\n",
    "               figsize=(6 * n_graph_per_row, 8 * n_graph_row),  # width x height in inches\n",
    "               dpi=80,                                         # resolution\n",
    "               facecolor='w',                                  # figure background color\n",
    "               edgecolor='k')                                  # figure border color\n",
    "\n",
    "    # Loop through each selected column (up to n_graph_shown)\n",
    "    for i, col_name in enumerate(columns_to_plot[:n_graph_shown]):\n",
    "        # Create a subplot in the grid\n",
    "        plt.subplot(n_graph_row, n_graph_per_row, i + 1)\n",
    "\n",
    "        # Get data of the current column\n",
    "        column_data = df_to_plot[col_name]\n",
    "\n",
    "        # Check if the column is numeric\n",
    "        if np.issubdtype(column_data.dtype, np.number):\n",
    "            # If numeric, plot histogram\n",
    "            column_data.hist()\n",
    "        else:\n",
    "            # If categorical, count unique values and plot bar chart\n",
    "            value_counts = column_data.value_counts()\n",
    "            value_counts.plot.bar()\n",
    "\n",
    "        # Label y-axis\n",
    "        plt.ylabel('counts')\n",
    "\n",
    "        # Rotate x-axis labels for better readability\n",
    "        plt.xticks(rotation=90)\n",
    "\n",
    "        # Set the title of the subplot using f-string\n",
    "        plt.title(f'{col_name} (column {i})')\n",
    "\n",
    "    # Adjust spacing between subplots to prevent overlap\n",
    "    plt.tight_layout(pad=1.0, w_pad=1.0, h_pad=1.0)\n",
    "\n",
    "    # Display the figure\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "Q6MzQ7fPq0_j",
    "outputId": "02720cef-6057-4956-9252-9a1e4e0092eb"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(30,30)\n",
    "plot_per_column_distribution(df, 79, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UO85Uh1UtjlV"
   },
   "source": [
    "## plot the bar graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJbmQzTSsWWS"
   },
   "outputs": [],
   "source": [
    "def bar_graph(feature):\n",
    "  df[feature].value_counts().plot(kind=\"bar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "id": "Qhrpo-4nuDuj",
    "outputId": "b5cbd79e-52c3-4b4e-b2f5-bea64c2bf209"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(15,15)\n",
    "bar_graph(\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "id": "GMtthLoduL5S",
    "outputId": "53cdeabc-ddbf-4fae-fe65-b82a017cf5c9"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "p=sns.distplot(a=df['Flow Duration'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPBhqNOtvK3c"
   },
   "source": [
    "## plotting the piechart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "bKTQcKGluk1q",
    "outputId": "821bdb08-3266-4b75-ee7d-6d6445c1f7ed"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.pie(df['Label'].value_counts(),labels=df['Label'].unique(),autopct=\"%0.2f%%\")\n",
    "plt.title(\"pie chart distribution of normal and abnormal labels\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620
    },
    "id": "J0gX8Zhkv2-i",
    "outputId": "98071b5b-88fb-443c-b29d-1f0b45d371f1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#increase the figure size\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "#piechart distribution of normal and abnormal labels\n",
    "labels=df['Label'].unique()\n",
    "sizes=df['Label'].value_counts()\n",
    "explode=(0.1,)*len(labels)#exploide all the slices slightly\n",
    "plt.pie(sizes,labels=labels,autopct=\"%0.2f%%\",explode=explode,startangle=90)\n",
    "plt.title(\"pie chart distribution of normal and abnormal labels\")\n",
    "plt.legend(labels,loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YOVo9HWO3z9b"
   },
   "outputs": [],
   "source": [
    "df.replace([np.inf,-np.inf],np.nan,inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kUcnFlD25N6q",
    "outputId": "5a7e8984-8b19-41d6-a8c7-d17a667495ed"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ckioO-M55PVi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#assuming df is your datafram with the given dataset\n",
    "#create a list of classes you want to keep all records for\n",
    "classes_to_keep = ['DoS GoldenEye','FTP-Patator','DoS slowloris','DoS Slowhttptest',\n",
    "                   'Bot','SSH-Patator','Web Attack � Brute Force','Web Attack � XSS',\n",
    "                   'Infiltration','Web Attack � Sql Injection','Heartbleed']\n",
    "\n",
    "#create  a list of classes you want to limit to 100000 records\n",
    "classes_to_limit=['BENIGN','DoS Hulk','PortScan','DDoS']\n",
    "#filter rows for classes to keep all records\n",
    "df_keep=df[df['Label'].isin(classes_to_keep)]\n",
    "#filter rows for classes to keep all records\n",
    "df_limit=df[df['Label'].isin(classes_to_limit)].groupby(\"Label\").head(50000)\n",
    "#combine the filtered rows\n",
    "result_df=pd.concat([df_keep,df_limit])\n",
    "#shuffle the resulting dataframe to mix the classes\n",
    "result_df=result_df.sample(frac=1,random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RNi5ZiuH8Goy",
    "outputId": "84a71dae-2ee2-4210-b434-4f0bda6b5bcc"
   },
   "outputs": [],
   "source": [
    "result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "id": "KmVB9zpy8Yz7",
    "outputId": "1acba9bc-9ca4-40c1-ed92-ceb7ce981709"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,20))\n",
    "#pie chart distribution of normal and abnormal labels\n",
    "labels=result_df['Label'].unique()\n",
    "sizes=result_df['Label'].value_counts()\n",
    "explode=(0.1,)*len(labels)#explode all slieces slightly\n",
    "plt.pie(sizes,labels=labels,autopct=\"%0.2f%%\",explode=explode,startangle=90)\n",
    "plt.title(\"pie chart distribution of normal and abnormal labels\")\n",
    "plt.legend(labels,loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCx8D_DX-HMV"
   },
   "source": [
    "## Label encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "mm-GY0079Viz",
    "outputId": "237f4b52-ac44-4e18-e934-dc5f9aec9f56"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#make acopy of your dataframe\n",
    "df_encoded=result_df.copy()\n",
    "#create alabel encoder object\n",
    "le=LabelEncoder()\n",
    "#fit and transform the label column and assign the transformed values to a new column\n",
    "df_encoded['Label']=le.fit_transform(result_df['Label'])\n",
    "#print the mapping of original labels to encoded values\n",
    "label_mapping=dict(zip(le.classes_,le.transform(le.classes_)))\n",
    "print(label_mapping)\n",
    "#display the modified dataframe\n",
    "print(\"\\n Encoded datarame:\")\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7iKi-xGz_LxT",
    "outputId": "941a7f68-083a-414f-bde9-a6c272c86d7f"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "#save the label encoder to file\n",
    "encoder_file_path='label_encoder.pkl'\n",
    "joblib.dump(le,encoder_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Og0kp07O_-ic"
   },
   "source": [
    "## making correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "id": "tCfsSqsP_8eq",
    "outputId": "083385c9-1d1c-4176-efc9-ba6627dadf2b"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#set the correlation threshold\n",
    "correlation_threshold=0.15\n",
    "#calulate the correlation matrix\n",
    "corr=df_encoded.corr()\n",
    "#filter column based on the correlation threshold\n",
    "columns_to_include=corr.columns[abs(corr['Label'])>=correlation_threshold]\n",
    "filtered_corr=corr.loc[columns_to_include,columns_to_include]\n",
    "#plot the filtered correlation heatmap\n",
    "fig,ax=plt.subplots(figsize=(15,15))\n",
    "colormap=sns.diverging_palette(150,50,as_cmap=True)\n",
    "sns.heatmap(filtered_corr,cmap=colormap,annot=True,fmt=\".2f\")\n",
    "plt.xticks(range(len(filtered_corr.columns)),filtered_corr.columns)\n",
    "plt.yticks(range(len(filtered_corr.columns)),filtered_corr.columns)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kCCOEhS1BkqT"
   },
   "outputs": [],
   "source": [
    "#split your data into X and Y\n",
    "X=df_encoded.drop('Label',axis=1)\n",
    "y=df_encoded['Label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "a6S-0GPsMgMe",
    "outputId": "9a7d10ad-367e-45e6-f8b0-076f231c27cc"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import pandas as pd\n",
    "\n",
    "#split the data into trainng and testing sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "#initialize random forest classifier\n",
    "rf_classifier=RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "\n",
    "#fit the model to the training data\n",
    "rf_classifier.fit(X_train,y_train)\n",
    "\n",
    "#get feature importances\n",
    "feature_importances=rf_classifier.feature_importances_\n",
    "\n",
    "#create dataframe with feature with names and their importances\n",
    "feature_importance_df=pd.DataFrame({'Feature':X.columns,'Importance':feature_importances})\n",
    "\n",
    "#sort the dataframe by importance in decending order\n",
    "feature_importance_df=feature_importance_df.sort_values(by='Importance',ascending=False)\n",
    "\n",
    "#select the top 20 features\n",
    "top_features=feature_importance_df.head(20)['Feature'].tolist()\n",
    "\n",
    "#filter your original dataframe to include only top 20 features\n",
    "df_top_features=df_encoded[top_features+['Label']]\n",
    "\n",
    "#display the dataframe with top features\n",
    "df_top_features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "cdCeZM1ER4G3",
    "outputId": "74a76741-2ed2-4327-e7f3-cc947d48e5da"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#create a bar plot of the top 20 features and their importances\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.barh(top_features,feature_importance_df.head(20)['Importance'],color='red')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Top 20 Features by Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "LxALBMqATWm3",
    "outputId": "74e859e7-bfae-4b6d-a37c-c1ef6de78656"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#assumming feature_importance-df is the datafram with feature importances\n",
    "#sort the dataframe by importance in  decending order\n",
    "feature_importance_df=feature_importance_df.sort_values(by='Importance',ascending=False)\n",
    "\n",
    "#create bar plot of all the features and their importance\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.barh(feature_importance_df['Feature'],feature_importance_df['Importance'],color=\"blue\")\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('All Features and their Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KH7VSzbcV91P",
    "outputId": "4c99ebdf-bf7b-49dd-a2cd-13efd20af904"
   },
   "outputs": [],
   "source": [
    "df_top_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lz6ndxPYWVWv"
   },
   "outputs": [],
   "source": [
    "#assumming the label is the target variable\n",
    "X_top_features=df_top_features.drop(['Label'],axis=1)\n",
    "y_top_features=df_top_features['Label']\n",
    "\n",
    "#split the data into training and testing sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_top_features,y_top_features,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-qEJMzb9XgnX",
    "outputId": "7054da5c-4b47-461d-e40b-7fb674a52e01"
   },
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HUS5NrRUXlA_",
    "outputId": "3bdcc50a-0b86-48ab-c55f-1827eafaee5c"
   },
   "outputs": [],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p60EYQ-5Yd_x"
   },
   "source": [
    "## Storing the top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gc639v1oXzJ-"
   },
   "outputs": [],
   "source": [
    "X_top_features.to_csv('X_top_features.csv',index=False)\n",
    "y_top_features.to_csv('y_top_features.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uUhXQw5WYU3n",
    "outputId": "945745aa-2565-4ffc-90d9-7ed8e7d40ec5"
   },
   "outputs": [],
   "source": [
    "print(\"Infinity values in X_train:\",np.any(np.isinf(X_train)))\n",
    "print(\"NaN values in X_train:\",np.any(np.isnan(X_train)))\n",
    "print(\"Infinity values in X_test:\",np.any(np.isinf(X_test)))\n",
    "print(\"NaN values in X_test:\",np.any(np.isnan(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBfFDg7SZBKH"
   },
   "outputs": [],
   "source": [
    "# #from sklearn.preprocessing import StandardScaler\n",
    "# scaler=StandardScaler()\n",
    "# X_train_scaled=scaler.fit_transform(X_train)\n",
    "# X_test_scaled=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d1sjR2YGZ7LI"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tV07Qj67chUw"
   },
   "outputs": [],
   "source": [
    "\n",
    "def print_all_accuracy_metric(algorithm,name):\n",
    "  #computing the accuracy ,f1score,precision and recall of the model performance\n",
    "  #predicting the target value from the model of the samples\n",
    "  y_train_log=algorithm.predict(X_train)\n",
    "  y_test_log=algorithm.predict(X_test)\n",
    "  acc_train_log=metrics.accuracy_score(y_train,y_train_log)\n",
    "\n",
    "  acc_test_log=metrics.accuracy_score(y_test,y_test_log)\n",
    "  print(name,\": Accuracy on training Data:{:.3f}\".format(acc_train_log))\n",
    "  print(name,\": Accuracy on test data:{:.3f}\".format(acc_test_log))\n",
    "  print()\n",
    "\n",
    "  f1_score_train_log=metrics.f1_score(y_train,y_train_log,average='macro')\n",
    "  f1_score_test_log=metrics.f1_score(y_test,y_test_log,average='macro')\n",
    "  print(name,\": F1 score on training data:{:.3f}\".format(f1_score_train_log))\n",
    "  print(name,\": F1 score on test data:{:.3f}\".format(f1_score_test_log))\n",
    "  print()\n",
    "\n",
    "  recall_score_train_log=metrics.recall_score(y_train,y_train_log,average='macro')\n",
    "  recall_score_test_log=metrics.recall_score(y_test,y_test_log,average='macro')\n",
    "  print(name,\": Recall score on training data:{:.3f}\".format(recall_score_train_log))\n",
    "  print(name,\": Recall score on test data:{:.3f}\".format(recall_score_test_log))\n",
    "  print()\n",
    "\n",
    "  precision_score_train_log=metrics.precision_score(y_train,y_train_log,average='macro')\n",
    "  precision_score_test_log=metrics.precision_score(y_test,y_test_log,average='macro')\n",
    "  print(name,\": Precision score on training data:{:.3f}\".format(precision_score_train_log))\n",
    "  print(name,\": precision socre on test dat:{:.3f}\".format(precision_score_test_log))\n",
    "  print()\n",
    "\n",
    "  print(\"\\n\\n Classification Report \\n\\n\")\n",
    "  print(metrics.classification_report(y_test,y_test_log))\n",
    "  print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6rzNyI2w5py"
   },
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0glDfU0yfwU"
   },
   "source": [
    " ## 1.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lu8rznLcgisg",
    "outputId": "315761cb-365f-4d85-e3a0-5acf90e5543b"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clfd=DecisionTreeClassifier(criterion='entropy',max_depth=4)\n",
    "clfd.fit(X_train,y_train)\n",
    "\n",
    "print_all_accuracy_metric(clfd,\"DecisionTreeClassifier\")\n",
    "#save the model using joblib\n",
    "joblib.dump(clfd,'DecisionTreeClassifier.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_Vgrqzn1dur"
   },
   "source": [
    "## 2. SVM(Support vector machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKqQQUexw2pb"
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# #create the SVM model\n",
    "# svm_model=SVC(kernel='linear',C=1.0)\n",
    "\n",
    "# #fit the model in the training data\n",
    "# svm_model.fit(X_train,y_train)\n",
    "\n",
    "# print_all_accuracy_metric(svm_model,'SVM')\n",
    "# #save the model using joblib\n",
    "# joblib.dump(svm_model,'SVM.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCvJTwLR3XM7"
   },
   "source": [
    "## 3. RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rqf_ch9K2hyz",
    "outputId": "c5d19eeb-d260-4e61-84a8-9d42c209d57a"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf=RandomForestClassifier(random_state=42)\n",
    "rf_clf.fit(X_train,y_train)\n",
    "print_all_accuracy_metric(rf_clf,'RandomForestClassifier')\n",
    "#save the model using joblib\n",
    "joblib.dump(rf_clf,'RandomForestClassifier.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHCasZ-r8LUr"
   },
   "source": [
    "## 3.KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jsku0hL88EEy",
    "outputId": "51a132dc-564e-4953-dc00-f4b07998e23c"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf=KNeighborsClassifier(n_neighbors=5)\n",
    "knn_clf.fit(X_train,y_train)\n",
    "# make the prediction on the test set\n",
    "y_pred=knn_clf.predict(X_test)\n",
    "print_all_accuracy_metric(knn_clf,'KNeighborsClassifier')\n",
    "\n",
    "#save the model using jolib\n",
    "joblib.dump(knn_clf,'KneighborsClassifier.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqdQQdgH_4Q7"
   },
   "source": [
    "## 4.Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YXqXSJQC9Dzr",
    "outputId": "0ff9b012-be25-47a0-9283-ad833da9a8a1"
   },
   "outputs": [],
   "source": [
    "# Naive Bayes classifier model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "nb=GaussianNB()\n",
    "#fit the model\n",
    "nb.fit(X_train,y_train)\n",
    "print_all_accuracy_metric(nb,'Naive Bayes')\n",
    "joblib.dump(nb,'GaussianNB.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AcdEDMTNA11B",
    "outputId": "39d7c108-ce28-4250-b96e-acedaaea0c00"
   },
   "outputs": [],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sICDOD7MH2C4"
   },
   "source": [
    "## 5 catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-pGAzCiPEHrX",
    "outputId": "31d9efa9-1960-4b06-b96a-1621cd3f61ca"
   },
   "outputs": [],
   "source": [
    "import catboost\n",
    "from catboost import CatBoostClassifier\n",
    "catboost_model=CatBoostClassifier(iterations=10,learning_rate=0.1,depth=6)\n",
    "catboost_model.fit(X_train,y_train)\n",
    "print_all_accuracy_metric(catboost_model,'CatBoostClassifier')\n",
    "joblib.dump(catboost_model,'CatBoostClassifier.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppj29A_xnLTJ"
   },
   "source": [
    "##6.Logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "srMevfecE3Ms",
    "outputId": "dd555aef-9ae3-40c6-d660-8ab4f72800cf"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg_model=LogisticRegression()\n",
    "logreg_model.fit(X_train,y_train)\n",
    "print_all_accuracy_metric(logreg_model,'LogisticRegression')\n",
    "joblib.dump(logreg_model,'LogisticRegression.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTvP6mUEsOWP"
   },
   "source": [
    "##7. Hybrid Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UDyvJ4vOnnWv",
    "outputId": "a11a9b92-2843-4585-a9f7-857c098824a6"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier,RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "#import or define print_all_accuracy_matric function\n",
    "#define the meta model\n",
    "meta_model=RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "#Define the base model\n",
    "logreg_model=LogisticRegression()\n",
    "clfd=DecisionTreeClassifier(criterion='entropy',max_depth=4)\n",
    "knn_clf=KNeighborsClassifier(n_neighbors=5)\n",
    "catboost_model=CatBoostClassifier(iterations=10,learning_rate=0.1,depth=6)\n",
    "#define the stacking ensemble model\n",
    "stacked_model=StackingClassifier(\n",
    "    estimators=[('DescisionTree',clfd),('LogisticRegression',logreg_model),('KNN',knn_clf),('CatBoostClassifier',catboost_model)],\n",
    "    final_estimator=meta_model,\n",
    "    cv=5# cross validation\n",
    ")\n",
    "#train the stacking ensemble model\n",
    "stacked_model.fit(X_train,y_train)\n",
    "#evalute the peroformance of the stacking ensemble model\n",
    "print_all_accuracy_metric(stacked_model,'Hybrid Model')\n",
    "#joblib.dump(stacked_model,'Hybrid Model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2CvpKJEBpDrB",
    "outputId": "a37a480e-5a9f-469c-f6db-49030821b538"
   },
   "outputs": [],
   "source": [
    "joblib.dump(stacked_model,'StackingEnsemble.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZAH4HgI1DzK"
   },
   "outputs": [],
   "source": [
    "# later, when you want to make predictions\n",
    "#load the model from the file\n",
    "loaded_model=joblib.load('StackingEnsemble.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdnWoN7G1klO"
   },
   "source": [
    "# Saving data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-GA8WzP1XPV",
    "outputId": "51d22304-5853-4277-8831-848300726b08"
   },
   "outputs": [],
   "source": [
    "print(X_top_features.iloc[0])\n",
    "print(\"\\n\\noutput:\",y_top_features.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1y1c40cG2NuG",
    "outputId": "d969b8d8-23bd-4c8b-cf01-0cf60f7d5110"
   },
   "outputs": [],
   "source": [
    "# make predictions using the loaded model\n",
    "#create a new dataframe with first row\n",
    "first_row_df=X_top_features.head(1)\n",
    "prediction=loaded_model.predict(first_row_df)\n",
    "#print the prediction\n",
    "print(f\"The predicted class is :{prediction[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TzEjGz8N-xl0",
    "outputId": "289ebf7a-39aa-4e97-cc6a-8a1ab195676f"
   },
   "outputs": [],
   "source": [
    "print(X_top_features.iloc[1])\n",
    "print(\"\\n\\noutput:\",y_top_features.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CvBTX3icAvcv",
    "outputId": "6fa29983-4c7f-4524-ed33-6fbd89b6a173"
   },
   "outputs": [],
   "source": [
    "#make prediction using the loaded model\n",
    "#create a new dataframe with the first row\n",
    "first_row_df=X_top_features.head(2).tail(1)\n",
    "prediction=loaded_model.predict(first_row_df)\n",
    "#print the prediction\n",
    "print(f\"The predicted class is :{prediction[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10W7VmZ6Bv-K"
   },
   "outputs": [],
   "source": [
    "first_row_df.to_csv('first_row_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 152
    },
    "id": "DRcN_uI2CPq8",
    "outputId": "504297cf-6b44-4f3c-d4ea-ac7cb2aaaf79"
   },
   "outputs": [],
   "source": [
    "first_row_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QIXz9VQ-CRGy"
   },
   "outputs": [],
   "source": [
    "#create a new datafram with the first row\n",
    "first_row_df=X_top_features.head(10)\n",
    "first_row_df.to_csv(\"first_x_10_row_df.csv\",index=False)\n",
    "#create a new dataframe with the first 10 row\n",
    "first_row_df=y_top_features.head(10)\n",
    "first_row_df.to_csv(\"first_y_10_row_df.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RdcRIZvIDBiO"
   },
   "outputs": [],
   "source": [
    "#create a new datafrma with the last row\n",
    "first_row_df=X_top_features.head(-10)\n",
    "first_row_df.to_csv(\"first_x_10_df_1.csv\",index=False)\n",
    "#create a new datframe with the first row\n",
    "first_row_df=y_top_features.head(-10)\n",
    "first_row_df.to_csv(\"first_y_10_df_1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPq2J4ZiD-Xb"
   },
   "outputs": [],
   "source": [
    "# Assuming X_top_features and y_top_feature are your dataframes\n",
    "middle_rows_X=X_top_features.loc[15:24]#select rows 16 to 25\n",
    "middle_rows_y=y_top_features.loc[15:24]\n",
    "\n",
    "#save the middle rows to CSV files\n",
    "middle_rows_X.to_csv(\"middle_x_10_rows.csv\",index=False)\n",
    "middle_rows_y.to_csv(\"middle_y_10_rows.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g7Z3OHztFfgU"
   },
   "outputs": [],
   "source": [
    "#create a new dataframe with the first row\n",
    "first_row_df=X_top_features.head(1)\n",
    "first_row_df.to_csv(\"first_x_row_df.csv\",index=False)\n",
    "\n",
    "first_row_df=y_top_features.head(1)\n",
    "first_row_df.to_csv(\"first_y_row_df.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yaSP8_q2Gehk"
   },
   "outputs": [],
   "source": [
    "#assumming X_top_features and y_top_features are your dataframes\n",
    "last_row_X=X_top_features.tail(10)\n",
    "last_row_y=y_top_features.tail(10)\n",
    "#save the last rows to the csv files\n",
    "last_row_X.to_csv(\"last_x_10_rows.csv\",index=False)\n",
    "last_row_y.to_csv(\"last_y_10_rows.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ceOWIASHeNH"
   },
   "source": [
    "# Live Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2GpcE1HHCJa"
   },
   "outputs": [],
   "source": [
    "# import joblib\n",
    "import pandas as pd\n",
    "#load the model from the file\n",
    "model_filename='StackingEnsemble.joblib'\n",
    "loaded_model=joblib.load(model_filename)\n",
    "#define the order and types of features manually\n",
    "feature_order=[\n",
    "    'Fwd Packet Length Max',\n",
    "    'Fwd Packet Length Mean',\n",
    "    'Bwd Packets/s',\n",
    "    'Total Length of Fwd Packets',\n",
    "    'Subflow Fwd Bytes',\n",
    "    'Flow Packets/s',\n",
    "    'Packet Length Std',\n",
    "    'Flow IAT Mean',\n",
    "    'Avg Fwd Segment Size',\n",
    "    'Flow IAT Max',\n",
    "    'Init_Win_bytes_backward',\n",
    "    'Avg Bwd Segment Size',\n",
    "    'Bwd Packet Length Mean',\n",
    "    'Flow Duration',\n",
    "    'Bwd Packet Length Std',\n",
    "    'Bwd Packet Length Max',\n",
    "    'Subflow Bwd Bytes',\n",
    "    'Total Length of Bwd Packets',\n",
    "    'Destination Port',\n",
    "    'Packet Length Variance'       ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fEz2jU3iKWeP"
   },
   "outputs": [],
   "source": [
    "#funtion to take user input and make prediction\n",
    "def make_prediction():\n",
    "    user_input = {}\n",
    "\n",
    "    # prompt the user for input for each feature\n",
    "    for column in feature_order:\n",
    "        value = input(f\"Enter value for {column}: \")\n",
    "        # convert to float (safe for most ML models)\n",
    "        user_input[column] = float(value)\n",
    "\n",
    "    # create a dataframe with the user input\n",
    "    user_data = pd.DataFrame(user_input, index=[0])\n",
    "\n",
    "    # make predictions using the loaded model\n",
    "    prediction = loaded_model.predict(user_data)\n",
    "\n",
    "    # print the prediction\n",
    "    print(f\"The predicted class is: {prediction[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFgUQYk7KYTg",
    "outputId": "c000ab91-5f9a-4384-8605-3912b55f56bb"
   },
   "outputs": [],
   "source": [
    "make_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ka3eAdbN7PA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCcjHO44PDQZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPCxKvxTCJ6y+ZE3bfiJP31",
   "include_colab_link": true,
   "mount_file_id": "1ArNBwKWS3jiRVyoFMVoOK6VxRA9NXvAd",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
